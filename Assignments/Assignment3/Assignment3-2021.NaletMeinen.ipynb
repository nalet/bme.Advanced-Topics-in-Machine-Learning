{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "innovative-governor",
   "metadata": {
    "id": "woVl0on9Z0oL"
   },
   "source": [
    "# ATML2021 Assignment 3 Nalet Meinen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "auburn-adelaide",
   "metadata": {
    "papermill": {
     "duration": 1.641545,
     "end_time": "2021-04-26T16:31:09.473744",
     "exception": false,
     "start_time": "2021-04-26T16:31:07.832199",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader, Subset, random_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms.functional as TF\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL.Image as Image\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import torchvision.utils as vutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "trying-identity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon May 24 14:15:54 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 440.118.02   Driver Version: 440.118.02   CUDA Version: 10.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce GTX 108...  Off  | 00000000:03:00.0 Off |                  N/A |\n",
      "|  0%   50C    P2    65W / 250W |   2458MiB / 11178MiB |      3%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  GeForce GTX 108...  Off  | 00000000:04:00.0 Off |                  N/A |\n",
      "| 70%   78C    P0    90W / 250W |     10MiB / 11175MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    0     24633      C   /home/ger/anaconda3/bin/python              1797MiB |\n",
      "|    0     31471      C   /home/ger/anaconda3/bin/python               651MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boring-vegetarian",
   "metadata": {
    "papermill": {
     "duration": 0.012601,
     "end_time": "2021-04-26T16:31:09.499900",
     "exception": false,
     "start_time": "2021-04-26T16:31:09.487299",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Here we implement the dataset class, create the training, validation and test sets and the dataloaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "numerous-diameter",
   "metadata": {
    "papermill": {
     "duration": 0.027418,
     "end_time": "2021-04-26T16:31:09.540847",
     "exception": false,
     "start_time": "2021-04-26T16:31:09.513429",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LabeledDataset(Dataset):\n",
    "    def __init__(self, folder_path, phase='train', transform=None):\n",
    "        super(LabeledDataset, self).__init__()\n",
    "        self.phase = phase\n",
    "        if self.phase == 'train':\n",
    "            file_path = os.path.join(folder_path, 'train_32x32_500_label.npz')\n",
    "        elif self.phase == 'val':\n",
    "            file_path = os.path.join(folder_path, 'test_32x32_2000_label.npz')\n",
    "        elif self.phase == 'test':\n",
    "            file_path = os.path.join(folder_path, 'test_32x32_competition.npy')\n",
    "        elif self.phase == 'unlabel':\n",
    "            file_path = os.path.join(folder_path, 'train_32x32_unlabel.npy')\n",
    "        else:\n",
    "            print('Unrecognized phase')\n",
    "        data_load = np.load(file_path)\n",
    "        \n",
    "        if self.phase != 'test' and self.phase != 'unlabel':\n",
    "            self.dataset = data_load['img']\n",
    "            self.labels = data_load['label'].astype('int64')\n",
    "        else:\n",
    "            self.dataset = data_load\n",
    "            \n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, index): \n",
    "        img_index = Image.fromarray(self.dataset[index,:])\n",
    "        if self.phase != 'test':\n",
    "            return self.transform(img_index), self.labels[index,0]\n",
    "        else:\n",
    "            return self.transform(img_index)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.dataset.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "secure-coating",
   "metadata": {
    "papermill": {
     "duration": 2.755011,
     "end_time": "2021-04-26T16:31:12.308810",
     "exception": false,
     "start_time": "2021-04-26T16:31:09.553799",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "transform=transforms.Compose([\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "                             ])\n",
    "\n",
    "train_set = LabeledDataset('.', phase='train', transform=transform)\n",
    "val_set = LabeledDataset('.', phase='val', transform=transform)\n",
    "test_set = LabeledDataset('.', phase='test', transform=transform)\n",
    "unlabel_set = LabeledDataset('.', phase='unlabel', transform=transform)\n",
    "\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "unlabel_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "romantic-abraham",
   "metadata": {
    "papermill": {
     "duration": 0.279227,
     "end_time": "2021-04-26T16:31:12.601148",
     "exception": false,
     "start_time": "2021-04-26T16:31:12.321921",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 7\n",
      "Image shape: torch.Size([3, 32, 32])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAaZElEQVR4nO2dbahlZ3XH/2vv83bfZiaTSeIQQ6OSDxWpUS5BSBFbW0lFiPmg6AcJNDh+MFDBfggp1PSbLVXxQ5GOTTAWqwmNYmhDawiWIJTUq43J2LH1hVSnGTKJMZ25L+dl77364ezQm3Sv/733vN1pnv8PLvecvc6z9zrP2evsc57/WWuZu0MI8donO2wHhBCLQcEuRCIo2IVIBAW7EImgYBciERTsQiRCa5rBZnYLgM8DyAH8lbt/mj2+11v2tbWjjTYmARZl2bh9NBqFYyqviCcWW7LYlmWzfW+cVPY04n9kYmPMyP6YHxOM42OYj3SnZI/NtgmfMvV/kSJ25MbmxZfQ39lutE4c7GaWA/gLAL8L4ByA75rZw+7+b9GYtbWjuPW232+0FWUcuC+8+GLj9ueffyEcs9nfDm3sBev0eqGtt9xp3l8evwlU5D2nKIrYSGhl8cuWWbMveZ7H+yO2nB2LjMuCOc5bzHfiB/OR7LPdajduZ2/qwRSO99dp3h8AsMvLrInO4b9/4C/DMdNcqm4C8BN3/5m7DwF8DcCtU+xPCDFHpgn2awH8Ytf9c/U2IcRlyDTB3vQ54v98bTGzU2a2YWYbO+SjtRBivkwT7OcAXLfr/usBPPvqB7n7aXdfd/f1pd7yFIcTQkzDNMH+XQA3mNkbzKwD4EMAHp6NW0KIWTPxary7F2Z2J4B/xFh6u8/df8jGZFmG5ZWlRttgRFZU28EKKFkFd7YMbrFIYh6vkFdV8wpoRlasqyo+VlkOYz/Y0m68IBwuJVdEGCqoBNgsewKA5wdfmfYifmJZTuYxi/1gc2yRjZw7rVZsG1/XAhuZx1nLcrGiFKsMU+ns7v4IgEem2YcQYjHoF3RCJIKCXYhEULALkQgKdiESQcEuRCJMtRp/UCwztLvdRtvOKJahBkF223AQj1kiCS2ra83yHwAsr8TjWr3m6SqDrDwAGA4GoW1E8mAyIuPw7LtAeiNSZEmkK/f4FBmN4ueWebMfZHeohvE85kSWa8fDULWaJzlQUetjkSQZKtmRJ8fS7AIp2EhGTpwxSc6b2AMhxGsJBbsQiaBgFyIRFOxCJIKCXYhEWOhqPABEOSM7OzvhmK3t5jz4jJQWuuqqK0Pb1ddcEdrW1lZCW4Xmld2XXmoumwUAmxYvFS9ZPP3dbpxw0e3EikGUFDLox2W/dnZiVcOL+HpQjOIV/qgEYFXGY7a3Yz+yduxHmCgFhCvdhcfzwRKliioed/TIsdCWt+OyWtEKf4uWOzt4ao2u7EIkgoJdiERQsAuRCAp2IRJBwS5EIijYhUiEhUpvDmAUyFcsMaETJBi027E8tbIaV7JdW10Nbb1eLOMUZbPc0SaySrcTT7GRhJalZZKssxQ/Nw8kmWEnloyWuvGxvCTSG0nkGQ6ajX0i8w1JRktFivI56cWSBwkoGZE9LZ8sCcmZj6TbTdQ9h7Ywm6B9la7sQiSCgl2IRFCwC5EICnYhEkHBLkQiKNiFSISppDczewbAJYx7BBXuvs4e7+4YBYXXijKWhiKJqttrrmcHAEu9WE7qkfp0rVghwSiQ3uJ6YLyOWJvULGOZbaxBpgW13zqteH49VjDBTpHRKJbKtnf6jdtZLTzrxzaWLVdWRLIL/DeSMZmzbLPQAjirGcfGBdvjFk9ARVt2NTMLnf233P2FGexHCDFH9DFeiESYNtgdwLfM7HtmdmoWDgkh5sO0H+NvdvdnzexqAI+a2Y/c/fHdD6jfBE4BwOqRo1MeTggxKVNd2d392fr/BQDfAHBTw2NOu/u6u68vLcUln4QQ82XiYDezFTNbe/k2gPcAODMrx4QQs2Waj/HXAPhGLQ+0APyNu/8DG1B5hX6/WZIZDknRw0Bm6JBss7xF5BOSTVSR9LtI4fGKvGc6y3aKNS8jWVlekvZEgfzTzuJjZT0yj3lsG5J2TaU32+wiE6/I/oIWYABQIc5UjGS0PKp8CqAi10CnbZxiE5Nn4/3RHR54dxMHu7v/DMBbJx0vhFgskt6ESAQFuxCJoGAXIhEU7EIkgoJdiERYaMHJqqqwHfR0Y73ehoHs0iYpaixjKCPZSVRZCYxMVmE9uVjBxv52LDWVg3hcO2uWoXKS5dXtxbYWyczLsvi5eSC9jcpYYh2NiI1MlhHNKyr0mBFJlGpo5ARx0iPOcrLP4HR0VlSSvJ4HPIwQ4rWGgl2IRFCwC5EICnYhEkHBLkQiLLb9U+UYTJAIE63S5iS5g62QsxwCJ0ugZVCDbjiMV4o3N2OVIc/i5wzEq8WsK1C31bwa3+vGySLLK6zVVGwbFbFisLW12bh9OGp+/QFgNIplhoLUu2ML07k3P+8RqVuXk9V4I9XkJqkzx5lsVISu7EIkgoJdiERQsAuRCAp2IRJBwS5EIijYhUiExUpviNvWsESHsmiWSbwTSxNlSeqZBfsDuKzV7zdLZdvbsZy0tbVN/Ij9Hw1Ju6MitnU7zXLk6nIsUx4ZxlV/i0EsDw5JUst2ILFWdO5JayiSdMOSl6K6dqzGH02iIrUNjSXCGDmxAu3QgiQeABPVoNOVXYhEULALkQgKdiESQcEuRCIo2IVIBAW7EImwp/RmZvcBeB+AC+7+lnrbcQAPALgewDMAPujuv9prX5kZup1uoy2SjADAR82yRbtN5BOWuTRB/S4A2N5ultEuXmzO8AKA/k6cGcZsUdYYAGTkPXp5uVlGyxBLP51OnBFXMknUSRG9YP6ZPLW82gtteYu0r2rH/ldVs3zFzp3e2nJoW1mKfSTqIPIJaiIyCTA8h9lxQsv/8iUAt7xq210AHnP3GwA8Vt8XQlzG7Bnsdb/1F1+1+VYA99e37wfw/tm6JYSYNZN+Z7/G3c8DQP3/6tm5JISYB3NfoDOzU2a2YWYbg35ctUUIMV8mDfbnzOwkANT/L0QPdPfT7r7u7uvdXlziSAgxXyYN9ocB3F7fvh3AN2fjjhBiXuxHevsqgHcBOGFm5wB8CsCnATxoZncA+DmAD+z3gD5BEb0skBOyLH6vynLW3idmRApf7gTZbVukqOTWZlxEcTgkBRaJ5LWyvBrbguKRK6uxnMRaPFUkDZAkqaEVZIetLMd+LJFin51uLL21AjkXAKoy2GcenzttcqycjGPnY56RVmWRTExah4VhRLLh9gx2d/9wYHr3XmOFEJcP+gWdEImgYBciERTsQiSCgl2IRFCwC5EICy446aiCQpCsN5sFkgaTjFqtyaS34SiWvIbD5iy10TAuoliRnmJZRjKverGctLoSS29Hjx1p3L7Ui7O1WDHEYT+WB53IclnWnInWJX50urFtZSUuitkiWW9Rcc6S+O456fdH9EYmvRmR7CIZLSrOCgAV0z0DdGUXIhEU7EIkgoJdiERQsAuRCAp2IRJBwS5EIixWenOP5SuS5RW9I3HpjWRyEdUi8g8AhoNmHwvSey0qvAgAK0FxSADoLcfS27Gja6HtyJFmWS4nctIg6GEHcKmpKklWVrfZxrK/Vom8trYWy40ZkbXKUXC+EUl0RLLNyorIa0R6Y4UgQ9mZZb2Rwp0RurILkQgKdiESQcEuRCIo2IVIBAW7EImw0NX4qnL0g8SKMkiQAYBWkFTBVtxzUoOOJXAMSQ26/qDZ9yJY8R0fK/ajTRI4jh07GtqOn2hOdgGATlD7bXs7rpPXHzS3tQKAnZ14HEteipJTVuISdOgwdYXVFLT43EHW/FoXZfyaoYzPj1Y+WcsxthpfBav4tF6jBy2j4hG6sguRCgp2IRJBwS5EIijYhUgEBbsQiaBgFyIR9tP+6T4A7wNwwd3fUm+7B8BHATxfP+xud39kr315VWEn6ORaDGIppLvULOMweY1JNawuHEtqqYLEBNZqqpWThBYmr115LLStrsa12iIZbacfy2sXt7ZC2zZpbZUToacdymikfRIVjlidv/jcKYpmW5QgAwAFkd46rVgu5VUP4+cWPW8jcl0RTSMZs58r+5cA3NKw/XPufmP9t2egCyEOlz2D3d0fB/DiAnwRQsyRab6z32lmT5nZfWZ2xcw8EkLMhUmD/QsA3gTgRgDnAXwmeqCZnTKzDTPbGJEWxUKI+TJRsLv7c+5e+vhH5l8EcBN57Gl3X3f39Tbpoy2EmC8TBbuZndx19zYAZ2bjjhBiXuxHevsqgHcBOGFm5wB8CsC7zOxGjBvXPAPgY/s5mHuFYtgs5bBMNAvqbTHpLcoKAoCKSCvEDeR5s+yytLQUjmF15k5cFS91HLsirrnGsryKreasvc3NWHrbvBjbBjuxRMVabPWCLEYjtfCQk3ZH5IUpSP3CqIZeQevMhSaA2Jw8NVaeLhqXGal3F5wDTLzcM9jd/cMNm+/da5wQ4vJCv6ATIhEU7EIkgoJdiERQsAuRCAp2IRJh4e2filGzTJKTbKLl5eYqhb1unP1VFrE81d+Jf8l36dJmaIukkKtPXBmOOXY0zmw7diyW11qtWETZ3u6Htl8+/0Lz9hd+FY7Z2oyLbHbb8RyvrsbS4fFjxxq3LxEpMicFJ1kGmBPNazhq1soGwXYAKApSSDOLZT5yCsNIi6osa/afdX+Kin2yplC6sguRCAp2IRJBwS5EIijYhUgEBbsQiaBgFyIRFiq9mRnyIFOqFWSUAXFPtIyMKYkGURBZjkk87UA+6XbjaVwOimUCwMpSnN9fIs42Gw1i6a0YNj+3kkwIqb+JgqRrjUbxPkeBtDUKpFcAGBCb22RSWRlkP2bohGPyoD/c2I94PpjsRfu2BRobk94mQVd2IRJBwS5EIijYhUgEBbsQiaBgFyIRFroaP66Q1bw6bRlzpdnGFivLoAYaABTExmrh5UH9tFaLJDmQumpm8epzQcpu97filkyDQXNSSzGIn3NJWl4hqOEGAEPSsqsf1K7b2YmTblhNu7Jg7bziOXYPxpHLnLEVd2KrSAW4Mkhcqfd64P2xencRurILkQgKdiESQcEuRCIo2IVIBAW7EImgYBciEfbT/uk6AF8G8DqMm9+cdvfPm9lxAA8AuB7jFlAfdPe40BnGtcLKqvmQLY9dGQaJDkzGYZ2hSpL5YUE9MADIA1tO6sWxfkFlGUtvo0BCA4ABkbwiia0kySIFqcfmWTxXw0Hs//ZWs3S4eSmWDVnvom6XFHgj5HlzwkuWx+dbpNYBe8i9RF5jbcUsC+rJkUFVeKzYh/1c2QsAn3T3XwfwDgAfN7M3A7gLwGPufgOAx+r7QojLlD2D3d3Pu/v369uXAJwFcC2AWwHcXz/sfgDvn5OPQogZcKDv7GZ2PYC3AXgCwDXufh4YvyEAuHrm3gkhZsa+g93MVgE8BOAT7n7xAONOmdmGmW0Uo/gnoEKI+bKvYDezNsaB/hV3/3q9+TkzO1nbTwK40DTW3U+7+7q7r7facWUWIcR82TPYbVyn6V4AZ939s7tMDwO4vb59O4Bvzt49IcSs2E/W280APgLgaTN7st52N4BPA3jQzO4A8HMAH9hzTwZU1qxrFER36Q+bpaZsK27V1GZyGMtAIsOiOnkd8oklqp8HAJnFNq9IdhWpGYcq0I1ImhTbX0XqwvVbsW1zq7lOXuu/ieRFXpZ+Lz5WJIkCQLfbbOv2Yn3NSN09oqBRq7MTKxoW1M/j+4uPs2ewu/t3yB7evdd4IcTlgX5BJ0QiKNiFSAQFuxCJoGAXIhEU7EIkwuILTgbpaE7ed4ZBdpjvxFJHK2jVBAA5kUhYRhmCzKuCtFYakIyyvB9nthWkCKQRyS7LgoKexl5qUviyJAUnh0SWC57bpYss6y1+zbqkZVfeJsUorVkWzdrxa0bqXsLaREIjrcN4wcnoeR+8quQkRxFCvMZQsAuRCAp2IRJBwS5EIijYhUgEBbsQibBY6c2ArBO8vxBpokBURJHIMRXJ/iHHGgQZdkAsn2RZrNUwCW17m8h8pH9Zbs1FFAHAgl56eUbGWOyHk7liRSwHw+bnbaxIaCf2sSSyFlHR0O40+9Fl6WtGijYGWZt7wSSxyGp01MFlOV3ZhUgEBbsQiaBgFyIRFOxCJIKCXYhEWOhqfJZnWF1ZarSNRvGKcBUkY7DV+FbQ9gfgK6pZGe9zVDX7sbkdrzCPRkQxILXOWLugguwzSiZpteP56PXild3MSJIMKV7XD9pXkbJqsO04SaYiq/FGen0VRbP/FVlxb7VInTyyCm50hZy0hjr4EGKcrv2TEOI1gIJdiERQsAuRCAp2IRJBwS5EIijYhUiEPaU3M7sOwJcBvA7jRjWn3f3zZnYPgI8CeL5+6N3u/gjbV55lWFlrlt6Gg1g+iSS2iiRiZIj354GEBgBOxhXhOCKrDIhUQ+Qfpr0VRB4cRjIl2V/FmhplTP+JbRbUAMyJBJi1iI2MA5Ews8BmpN6dEWnWyHwYu3aShKJQsiNyY8wU7Z8wrkb4SXf/vpmtAfiemT1a2z7n7n8+gUdCiAWzn15v5wGcr29fMrOzAK6dt2NCiNlyoO/sZnY9gLcBeKLedKeZPWVm95nZFbN2TggxO/Yd7Ga2CuAhAJ9w94sAvgDgTQBuxPjK/5lg3Ckz2zCzjWGf1AwXQsyVfQW7jbsSPATgK+7+dQBw9+fcvXT3CsAXAdzUNNbdT7v7uruvd3rNi3NCiPmzZ7CbmQG4F8BZd//sru0ndz3sNgBnZu+eEGJW7Gc1/mYAHwHwtJk9WW+7G8CHzexGjPWXZwB8bK8dZXmO1SNrjbYiyJIC4syxitR3c1LDbUiOVZSkDlpoiWFtf6JsPoCrLqzmnQW9i1rd+Hl1ncg1HVKDjoxD1mzr9JrbMQFAl3zya3fica02yR4MpbdwCC/vxtTSPSrNTXbA2bGf1fjvoNkbqqkLIS4v9As6IRJBwS5EIijYhUgEBbsQiaBgFyIRFlpw0jJDu9ssoeSkaGDQwQcg0k85jOW1NikoSP3oNNtGpPBiVsY+FsO4mKMF0hUA5CQrqwqyzdBubgsFAK1e7EdJJMyKtNjy4DrSbsV+LC3F0lu3F49jCXGtdjBX7DLHshEpk+l5FuiArPXWJOjKLkQiKNiFSAQFuxCJoGAXIhEU7EIkgoJdiERYqPQGxEX5clZsMJDYMiJPlSQTKgsywwAg78TjiqJZ/vGSSCREuipGpI8ayehjtnYwJ6wfWhbJUwCIqhjKa8zWbffCMT2S2dYmr0uWx/MRSalRIUoglsLGttCEidPlJvBjEnRlFyIRFOxCJIKCXYhEULALkQgKdiESQcEuRCIsVnpzQ1U1v78QFQ3ZBBJEnsdPrUPbhsUSScebB2akbxhrlVaSnm07O4PYth3b8k7zXLWCfnljWyxdlayoJys4GfTMY9Jbh6Sv5W1yLIslzKg2J8sqnJw5VLGcIbqyC5EICnYhEkHBLkQiKNiFSAQFuxCJsOdqvJn1ADwOoFs//m/d/VNmdhzAAwCux7j90wfd/Vd77i94f6lYwki4WhmvFJM8B5pAw2rQReNapKYdW6lnq/FOxjFb1JKJtZoqyUo9W40vSQJQVD+tRZSVNkteyuNxFVnpnkTJoThL/mGKAZmrYNysr8T72d8AwG+7+1sxbs98i5m9A8BdAB5z9xsAPFbfF0JcpuwZ7D5ms77brv8cwK0A7q+33w/g/fNwUAgxG/bbnz2vO7heAPCouz8B4Bp3Pw8A9f+r5+alEGJq9hXs7l66+40AXg/gJjN7y34PYGanzGzDzDYGO1sTuimEmJYDrQG4+0sA/gnALQCeM7OTAFD/vxCMOe3u6+6+3l1amc5bIcTE7BnsZnaVmR2rby8B+B0APwLwMIDb64fdDuCbc/JRCDED9pMIcxLA/WaWY/zm8KC7/52Z/TOAB83sDgA/B/CB/RxwopY20RAiqzApj6YrEFkrGlkUpI0T8ZFNRasbtztaIQkjHkpDLKEl9sNYsguRocJZjt1ARq49LG/FQZJ8AsmuImOMyWusNdRkJnhgZWMmqU+3Z7C7+1MA3taw/ZcA3n3gIwohDgX9gk6IRFCwC5EICnYhEkHBLkQiKNiFSASbSAqb9GBmzwP4z/ruCQAvLOzgMfLjlciPV/L/zY9fc/ermgwLDfZXHNhsw93XD+Xg8kN+JOiHPsYLkQgKdiES4TCD/fQhHns38uOVyI9X8prx49C+swshFos+xguRCIcS7GZ2i5n9u5n9xMwOrXadmT1jZk+b2ZNmtrHA495nZhfM7MyubcfN7FEz+3H9/4pD8uMeM/uvek6eNLP3LsCP68zs22Z21sx+aGZ/UG9f6JwQPxY6J2bWM7N/MbMf1H78Sb19uvlw94X+YdwE7KcA3gigA+AHAN68aD9qX54BcOIQjvtOAG8HcGbXtj8DcFd9+y4Af3pIftwD4A8XPB8nAby9vr0G4D8AvHnRc0L8WOicYJwfvFrfbgN4AsA7pp2Pw7iy3wTgJ+7+M3cfAvgaxsUrk8HdHwfw4qs2L7yAZ+DHwnH38+7+/fr2JQBnAVyLBc8J8WOh+JiZF3k9jGC/FsAvdt0/h0OY0BoH8C0z+56ZnTokH17mcirgeaeZPVV/zJ/714ndmNn1GNdPONSipq/yA1jwnMyjyOthBHtTiY3DkgRudve3A/g9AB83s3cekh+XE18A8CaMewScB/CZRR3YzFYBPATgE+5+cVHH3YcfC58Tn6LIa8RhBPs5ANftuv96AM8egh9w92fr/xcAfAPjrxiHxb4KeM4bd3+uPtEqAF/EgubEzNoYB9hX3P3r9eaFz0mTH4c1J/WxX8IBi7xGHEawfxfADWb2BjPrAPgQxsUrF4qZrZjZ2su3AbwHwBk+aq5cFgU8Xz6Zam7DAubExgXV7gVw1t0/u8u00DmJ/Fj0nMytyOuiVhhftdr4XoxXOn8K4I8OyYc3YqwE/ADADxfpB4CvYvxxcITxJ507AFyJcRutH9f/jx+SH38N4GkAT9Un18kF+PGbGH+VewrAk/Xfexc9J8SPhc4JgN8A8K/18c4A+ON6+1TzoV/QCZEI+gWdEImgYBciERTsQiSCgl2IRFCwC5EICnYhEkHBLkQiKNiFSIT/AQf+QF3z0sdpAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_image = train_set[0]\n",
    "plt.imshow(sample_image[0].permute(1,2,0)*0.5 + 0.5)\n",
    "print(\"Label:\", sample_image[1])\n",
    "print(\"Image shape:\", sample_image[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bearing-barrel",
   "metadata": {
    "papermill": {
     "duration": 0.014937,
     "end_time": "2021-04-26T16:31:12.630729",
     "exception": false,
     "start_time": "2021-04-26T16:31:12.615792",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let us define a fully-convolutional classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "agreed-header",
   "metadata": {
    "papermill": {
     "duration": 0.028832,
     "end_time": "2021-04-26T16:31:12.674193",
     "exception": false,
     "start_time": "2021-04-26T16:31:12.645361",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator(\n",
      "  (main): Sequential(\n",
      "    (0): ConvTranspose2d(128, 512, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): ConvTranspose2d(128, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (10): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): ConvTranspose2d(32, 3, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (13): Tanh()\n",
      "  )\n",
      ")\n",
      "Discriminator(\n",
      "  (layer01): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(2, 2), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  )\n",
      "  (layer02): Sequential(\n",
      "    (0): Conv2d(64, 128, kernel_size=(2, 2), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  )\n",
      "  (layer03): Sequential(\n",
      "    (0): Conv2d(128, 1024, kernel_size=(2, 2), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  )\n",
      "  (layer04): Sequential(\n",
      "    (0): Conv2d(1024, 128, kernel_size=(2, 2), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  )\n",
      "  (layer05): Sequential(\n",
      "    (0): Conv2d(128, 1, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): Sigmoid()\n",
      "  )\n",
      ")\n",
      "ClassifierNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (layer1): Sequential(\n",
      "    (0): Block(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (1): Block(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Block(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Block(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Block(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Block(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Block(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Block(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.ConvTranspose2d(128, 512, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.ConvTranspose2d(512, 256, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.ConvTranspose2d(256, 128, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.ConvTranspose2d(128, 32, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.ConvTranspose2d(32, 3, 4, 1, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.layer01 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 2, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        )\n",
    "        self.layer02 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, 2, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        )\n",
    "        self.layer03 = nn.Sequential(\n",
    "            nn.Conv2d(128, 1024, 2, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        )\n",
    "        self.layer04 = nn.Sequential(\n",
    "            nn.Conv2d(1024, 128, 2, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        )\n",
    "        self.layer05 = nn.Sequential(\n",
    "            nn.Conv2d(128, 1, 5, 1, 1, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = self.layer01(input)\n",
    "        output = self.layer02(output)\n",
    "        output = self.layer03(output)\n",
    "        output = self.layer04(output)\n",
    "        output = self.layer05(output)\n",
    "        return output\n",
    "\n",
    "class Block(nn.Module):\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(Block, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, planes, kernel_size=1, stride=stride, bias=False), \n",
    "                nn.BatchNorm2d(planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = nn.functional.relu(self.bn1(self.conv1(input)))\n",
    "        output = self.bn2(self.conv2(output))\n",
    "        output += self.shortcut(input)\n",
    "        output = nn.functional.relu(output)\n",
    "        return output\n",
    "\n",
    "class ClassifierNet(nn.Module):\n",
    "\n",
    "    def __init__(self, num_blocks=[2, 2, 2, 2]):\n",
    "        super(ClassifierNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(512, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(512, 10)\n",
    "\n",
    "    def _make_layer(self, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(Block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = nn.functional.relu(self.bn1(self.conv1(input)))\n",
    "        output = self.layer1(output)\n",
    "        output = self.layer2(output)\n",
    "        output = self.layer3(output)\n",
    "        output = self.layer4(output)\n",
    "        output = nn.functional.avg_pool2d(output, 4)\n",
    "        output = torch.flatten(output, 1)\n",
    "        output = self.linear(output)\n",
    "        return nn.functional.log_softmax(output, dim=1)\n",
    "    \n",
    "print(Generator())\n",
    "print(Discriminator())\n",
    "print(ClassifierNet())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "blind-haven",
   "metadata": {
    "papermill": {
     "duration": 0.106043,
     "end_time": "2021-04-26T16:31:12.857070",
     "exception": false,
     "start_time": "2021-04-26T16:31:12.751027",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model output shape: torch.Size([4, 10])\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = ClassifierNet().to(device)\n",
    "\n",
    "noise = torch.randn(4, 3, 32, 32, device=device)\n",
    "out = model(noise)\n",
    "print(\"Model output shape:\", out.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "varying-module",
   "metadata": {
    "papermill": {
     "duration": 0.014656,
     "end_time": "2021-04-26T16:31:12.888505",
     "exception": false,
     "start_time": "2021-04-26T16:31:12.873849",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Define the criterion and the optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "normal-father",
   "metadata": {
    "papermill": {
     "duration": 0.02404,
     "end_time": "2021-04-26T16:31:12.927463",
     "exception": false,
     "start_time": "2021-04-26T16:31:12.903423",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pointed-season",
   "metadata": {
    "papermill": {
     "duration": 0.014811,
     "end_time": "2021-04-26T16:31:12.957904",
     "exception": false,
     "start_time": "2021-04-26T16:31:12.943093",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Train the model for 20 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "refined-incentive",
   "metadata": {
    "papermill": {
     "duration": 39.208887,
     "end_time": "2021-04-26T16:31:52.181841",
     "exception": false,
     "start_time": "2021-04-26T16:31:12.972954",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af5270a72339496ca1b9a22746f4606b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for epoch in tqdm(range(200)):\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 10 == 9:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, loss.item()))\n",
    "            running_loss = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exotic-democrat",
   "metadata": {
    "papermill": {
     "duration": 0.021433,
     "end_time": "2021-04-26T16:31:52.225521",
     "exception": false,
     "start_time": "2021-04-26T16:31:52.204088",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Test the model on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "diverse-blair",
   "metadata": {
    "papermill": {
     "duration": 1.503937,
     "end_time": "2021-04-26T16:31:53.751798",
     "exception": false,
     "start_time": "2021-04-26T16:31:52.247861",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 2000 validation images: 39 %\n",
      "Val loss 3.776410222053528\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "total_loss = 0\n",
    "with torch.no_grad():\n",
    "    for data in val_loader:\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "            \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "print('Accuracy of the network on the 2000 validation images: %d %%' % (\n",
    "    100 * correct / total))\n",
    "print('Val loss', total_loss / len(val_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "looking-composite",
   "metadata": {
    "papermill": {
     "duration": 0.047805,
     "end_time": "2021-04-26T16:31:12.736554",
     "exception": false,
     "start_time": "2021-04-26T16:31:12.688749",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "231def13352c4a05a6d116ce58f9153f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Number of training epochs\n",
    "num_epochs = 1000\n",
    "\n",
    "# Learning rate for optimizers\n",
    "lr = 0.0002\n",
    "\n",
    "# Beta1 hyperparam for Adam optimizers\n",
    "beta1 = 0.5\n",
    "\n",
    "netG = Generator().to(device)\n",
    "netD = Discriminator().to(device)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "fixed_noise = torch.randn(64, 128, 1, 1, device=device)\n",
    "\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "\n",
    "img_list = []\n",
    "G_losses = []\n",
    "D_losses = []\n",
    "iters = 0\n",
    "\n",
    "pbar = tqdm(range(num_epochs))\n",
    "for epoch in pbar:\n",
    "    for i, data in enumerate(unlabel_loader):\n",
    "        # maximize log(D(x)) + log(1 - D(G(z)))\n",
    "        netD.zero_grad()\n",
    "        real_cpu = data[0].to(device)\n",
    "        b_size = real_cpu.size(0)\n",
    "        label = torch.full((b_size,), real_label, dtype=torch.float, device=device)\n",
    "        # Forward pass real batch through D\n",
    "        output = netD(real_cpu).view(-1)\n",
    "        # Calculate loss on all-real batch\n",
    "        errD_real = criterion(output, label)\n",
    "        errD_real.backward()\n",
    "        D_x = output.mean().item()\n",
    "\n",
    "        ## Train with all-fake batch\n",
    "        # Generate batch of latent vectors\n",
    "        noise = torch.randn(b_size, 128, 1, 1, device=device)\n",
    "        # Generate fake image batch with G\n",
    "        fake = netG(noise)\n",
    "        label.fill_(fake_label)\n",
    "        # Classify all fake batch with D\n",
    "        output = netD(fake.detach()).view(-1)\n",
    "        # Calculate D's loss on the all-fake batch\n",
    "        errD_fake = criterion(output, label)\n",
    "        # Calculate the gradients for this batch\n",
    "        errD_fake.backward()\n",
    "        D_G_z1 = output.mean().item()\n",
    "        # Add the gradients from the all-real and all-fake batches\n",
    "        errD = errD_real + errD_fake\n",
    "        # Update D\n",
    "        optimizerD.step()\n",
    "\n",
    "        # maximize log(D(G(z)))\n",
    "        netG.zero_grad()\n",
    "        label.fill_(real_label) \n",
    "        output = netD(fake).view(-1)\n",
    "        # Calculate G's loss based on this output\n",
    "        errG = criterion(output, label)\n",
    "        # Calculate gradients for G\n",
    "        errG.backward()\n",
    "        D_G_z2 = output.mean().item()\n",
    "        # Update G\n",
    "        optimizerG.step()\n",
    "\n",
    "        pbar.set_description('[%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n",
    "                            % (i, len(unlabel_loader), errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n",
    "        \n",
    "        # Save Losses for plotting later\n",
    "        G_losses.append(errG.item())\n",
    "        D_losses.append(errD.item())\n",
    "    \n",
    "        iters += 1\n",
    "\n",
    "    with torch.no_grad():\n",
    "        fake = netG(fixed_noise).detach().cpu()\n",
    "        img_list.append(vutils.make_grid(fake, padding=2, normalize=True))\n",
    "        \n",
    "torch.save(netD.state_dict(), \"unsuperviced_pre-training.pht\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continuing-industry",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.title(\"Generator and Discriminator Loss During Training\")\n",
    "plt.plot(G_losses,label=\"G\")\n",
    "plt.plot(D_losses,label=\"D\")\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hearing-invention",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_batch = next(iter(unlabel_loader))\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.subplot(1,2,1)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Real Images\")\n",
    "plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=5, normalize=True).cpu(),(1,2,0)))\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Fake Images\")\n",
    "plt.imshow(np.transpose(img_list[-1],(1,2,0)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "particular-victorian",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, loss_fn):\n",
    "    '''\n",
    "    Trains the model for one epoch\n",
    "    '''\n",
    "    model.train()\n",
    "    losses = []\n",
    "    n_correct = 0\n",
    "    for iteration, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        output = model(images)\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_fn(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "        n_correct += torch.sum(output.argmax(1) == labels).item()\n",
    "    accuracy = 100.0 * n_correct / len(train_loader.dataset)\n",
    "    return np.mean(np.array(losses)), accuracy\n",
    "            \n",
    "def test(model, test_loader, loss_fn):\n",
    "    '''\n",
    "    Tests the model on data from test_loader\n",
    "    '''\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    n_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            output = model(images)\n",
    "            loss = loss_fn(output, labels)\n",
    "            test_loss += loss.item()\n",
    "            n_correct += torch.sum(output.argmax(1) == labels).item()\n",
    "\n",
    "    average_loss = test_loss / len(test_loader)\n",
    "    accuracy = 100.0 * n_correct / len(test_loader.dataset)\n",
    "    return average_loss, accuracy\n",
    "\n",
    "\n",
    "def fit(taskname,train_dataloader, val_dataloader, model, optimizer, loss_fn, n_epochs):\n",
    "\n",
    "    train_losses, train_accuracies = [], []\n",
    "    val_losses, val_accuracies = [], []\n",
    "\n",
    "    last_val_accuracies = 0\n",
    "    best_epoch = 1\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        train_loss, train_accuracy = train(model, train_dataloader, optimizer, loss_fn)\n",
    "        val_loss, val_accuracy = test(model, val_dataloader, loss_fn)\n",
    "        train_losses.append(train_loss)\n",
    "        train_accuracies.append(train_accuracy)\n",
    "        val_losses.append(val_loss)\n",
    "        val_accuracies.append(val_accuracy)\n",
    "\n",
    "        print(\"\"\"Epoch {}/{}: train_loss: {:.4f}, train_accuracy: {:.4f}, val_loss: {:.4f}, val_accuracy: {:.4f}\"\"\".format(\n",
    "                        epoch+1, n_epochs, train_losses[-1], train_accuracies[-1], val_losses[-1], val_accuracies[-1]))\n",
    "\n",
    "        if val_accuracies[-1] > last_val_accuracies:\n",
    "            torch.save(model.state_dict(), str(taskname)+\".pht\")\n",
    "            best_epoch = epoch+1\n",
    "            last_val_accuracies = val_accuracies[-1]\n",
    "\n",
    "    best_model = ClassifierNet()\n",
    "    best_model = best_model.to(device)\n",
    "    best_model.load_state_dict(torch.load(str(taskname)+\".pht\"))\n",
    "\n",
    "    return train_losses, train_accuracies, val_losses, val_accuracies, loss_fn, best_model, best_epoch\n",
    "\n",
    "def plot_results(train_results, test_dataloader, val_dataloader):\n",
    "    train_losses, train_accuracies, val_losses, val_accuracies, loss_fn, best_model, best_epoch = train_results\n",
    "\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(15, 4))\n",
    "\n",
    "    axs[0].plot(np.arange(len(train_losses)), train_losses)\n",
    "    axs[0].plot(np.arange(len(val_losses)), val_losses)\n",
    "    axs[0].legend(['train_loss', 'val_loss'])\n",
    "    axs[0].set_xlabel('epoch')\n",
    "    axs[0].set_ylabel('loss value')\n",
    "    axs[0].set_title('Train/val loss')\n",
    "\n",
    "    axs[1].plot(np.arange(len(train_accuracies)), train_accuracies)\n",
    "    axs[1].plot(np.arange(len(val_accuracies)), val_accuracies)\n",
    "    axs[1].legend(['train_acc', 'val_acc'])\n",
    "    axs[1].set_xlabel('epoch')\n",
    "    axs[1].set_ylabel('accuracy')\n",
    "    axs[1].set_title('Train/val accuracy')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    m_loss, accuracy = test(best_model, val_dataloader, loss_fn)\n",
    "    print(\"Best Epoch:\", best_epoch, \"Average loss:\", m_loss, \"Accuracy:\", accuracy)\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "def test_pretrained(taskname,num_blocks,val_dataloader,loss_fn):\n",
    "    best_model = ClassifierNet(num_blocks)\n",
    "    best_model = best_model.to(device)\n",
    "    best_model.load_state_dict(torch.load(str(taskname)+\".pht\"))\n",
    "    m_loss, accuracy = test(best_model, val_dataloader, loss_fn)\n",
    "    print(\"Model:\", taskname, \"Average loss:\", m_loss, \"Accuracy:\", accuracy)\n",
    "\n",
    "def show_validation_errors(taskname,num_blocks,test_loader,num_images=10):\n",
    "    model = ClassifierNet(num_blocks)\n",
    "    model = model.to(device)\n",
    "    model.load_state_dict(torch.load(str(taskname)+\".pht\"))\n",
    "\n",
    "    model.eval()\n",
    "    images_so_far = 0\n",
    "    fig = plt.figure()\n",
    "\n",
    "    def imshow(inp, title=None):\n",
    "        \"\"\"Imshow for Tensor.\"\"\"\n",
    "        inp = inp.numpy().transpose((1, 2, 0))\n",
    "        mean = np.array(_t_mean)\n",
    "        std = np.array(_t_std)\n",
    "        inp = std * inp + mean\n",
    "        inp = np.clip(inp, 0, 1)\n",
    "        plt.figure(figsize=(5,5))\n",
    "        plt.imshow(inp)\n",
    "        if title is not None:\n",
    "            plt.title(title)\n",
    "        plt.pause(0.001)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            output = model(images)\n",
    "            _, preds = torch.max(output, 1)\n",
    "            \n",
    "            for j in range(images.size()[0]):\n",
    "                if(labels.cpu().data[j] == preds[j]):\n",
    "                    continue\n",
    "                images_so_far += 1\n",
    "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
    "                ax.axis('off')\n",
    "                ax.set_title('actual: {}, predicted: {}'.format(labels.cpu().data[j], preds[j]))\n",
    "                imshow(images.cpu().data[j])\n",
    "\n",
    "                if images_so_far == num_images:\n",
    "                    return\n",
    "\n",
    "    average_loss = test_loss / len(test_loader)\n",
    "    accuracy = 100.0 * n_correct / len(test_loader.dataset)\n",
    "    return average_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aggressive-youth",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transfer_model(): \n",
    "    #Preparations\n",
    "    pretrained_model = Discriminator()\n",
    "    pretrained_model = pretrained_model.to(device)\n",
    "    pretrained_model.load_state_dict(torch.load(\"unsuperviced_pre-training.pht\"))\n",
    "\n",
    "    #Transfer\n",
    "    transfer_model = ClassifierNet()\n",
    "    transfer_model.layer01 = pretrained_model.layer01\n",
    "    transfer_model.layer02 = pretrained_model.layer02\n",
    "    transfer_model.layer03 = pretrained_model.layer03\n",
    "    transfer_model.layer04 = pretrained_model.layer04\n",
    "    return transfer_model\n",
    "\n",
    "# train_dataloader = DataLoader(dataset_train_labelled, batch_size=batch_size, shuffle=True, num_workers=workers)\n",
    "# val_dataloader = DataLoader(dataset_validation_labelled, batch_size=batch_size, shuffle=False, num_workers=workers)\n",
    "n_epochs = 150\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "experienced-intervention",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model = ClassifierNet()\n",
    "model = model.to(device)\n",
    "model.load_state_dict(get_transfer_model().state_dict())\n",
    "\n",
    "model.layer01.requires_grad = False\n",
    "model.layer02.requires_grad = False\n",
    "model.layer03.requires_grad = False\n",
    "model.layer04.requires_grad = False\n",
    "\n",
    "lr = 0.001\n",
    "\n",
    "optimizer = optim.Adam(model.classifier.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "\n",
    "fixed_features_results = fit(\"fixed_features\", train_loader, val_loader, model, optimizer, loss_fn, n_epochs)\n",
    "plot_results(fixed_features_results, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solar-bahrain",
   "metadata": {
    "papermill": {
     "duration": 0.023418,
     "end_time": "2021-04-26T16:31:53.797572",
     "exception": false,
     "start_time": "2021-04-26T16:31:53.774154",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We expect similar accuracy on the leaderboard. However, the overfitting is clear. Let us prepare the submission file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "known-integer",
   "metadata": {
    "papermill": {
     "duration": 16.195719,
     "end_time": "2021-04-26T16:32:10.016208",
     "exception": false,
     "start_time": "2021-04-26T16:31:53.820489",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions = np.array([])\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        inputs = data\n",
    "        inputs = inputs.to(device)\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "            \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        predictions = np.append(predictions, predicted.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "listed-boundary",
   "metadata": {
    "papermill": {
     "duration": 0.035538,
     "end_time": "2021-04-26T16:32:10.074574",
     "exception": false,
     "start_time": "2021-04-26T16:32:10.039036",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame({\n",
    "    \"Id\": np.arange(predictions.size),\n",
    "    \"Category\": predictions},\n",
    "    dtype=np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "constant-reflection",
   "metadata": {
    "papermill": {
     "duration": 0.078572,
     "end_time": "2021-04-26T16:32:10.175270",
     "exception": false,
     "start_time": "2021-04-26T16:32:10.096698",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions.to_csv(\"baseline_predictions.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 73.086541,
   "end_time": "2021-04-26T16:32:11.802556",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-04-26T16:30:58.716015",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
