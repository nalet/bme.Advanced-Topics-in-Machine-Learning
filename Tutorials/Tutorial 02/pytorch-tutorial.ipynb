{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plan for today:\n",
    "- PyTorch installation\n",
    "- PyTorch basics\n",
    "- Data loading and simple models in PyTorch (linear regression, images of digits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install pytorch and torchvision\n",
    "Installation instruction: https://pytorch.org/  \n",
    "e.g. with conda:  \n",
    "`conda install pytorch torchvision -c pytorch`  \n",
    "or with pip:  \n",
    "`pip3 install https://download.pytorch.org/whl/cpu/torch-1.0.1.post2-cp36-cp36m-linux_x86_64.whl`  \n",
    "`pip3 install torchvision`  \n",
    "  \n",
    "Different commands for GPU version -> all in PyTorch website"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch resources\n",
    "- https://pytorch.org/tutorials/\n",
    "- https://github.com/yunjey/pytorch-tutorial\n",
    "- http://cs231n.stanford.edu/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic datatype in PyTorch is a Tensor (syntax very similar to numpy array). https://pytorch.org/docs/stable/tensors.html  \n",
    "**A `torch.Tensor` is a multi-dimensional matrix containing elements of a single data type.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.tensor([1, 2, 3])\n",
    "print(data)\n",
    "print(data.size())\n",
    "print(data.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.tensor([[1, 2, 3], [4, 5, 6]], dtype=torch.float32)\n",
    "print(data)\n",
    "print(data.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.zeros((3, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.ones((3, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random numbers\n",
    "torch.rand(3, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CPU vs GPU (CUDA)\n",
    "Tensors can live on CPU or on GPU if torch is installed with Nvidia CUDA support. *CUDA tensors allow for much faster computation!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make code compatible with both GPU and CPU, you can set the device at the beginning of your code and always transfer your tensors/models to this device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor(5, device=device)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = a.to(device)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = a.to(torch.device('cpu'))\n",
    "print(a)\n",
    "print(a.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor(5.0)\n",
    "b = torch.tensor(2.0)\n",
    "print(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = a + b\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = a - b\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = a * b\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = a / b\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrix computations\n",
    "a = torch.rand(3, 4)\n",
    "b = torch.rand(4, 1)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = a.matmul(b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(c + torch.rand(3, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch computational graph\n",
    "Important property of PyTorch tensor operations - they create a **dynamic computational graph**.  \n",
    "The tensor **c** knows that how it was created from **a** and **b**.  \n",
    "Thanks to this, derivatives (gradients) can be computed for tensors.  \n",
    "Example:  \n",
    "<img src=\"tree-eval.png\" alt=\"Drawing\" style=\"width: 600px;\"/>  \n",
    "*Source: http://colah.github.io/posts/2015-08-Backprop/ - good blog post to understand backpropagation*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute for a=2, b=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a and b\n",
    "# Compute c, d, e\n",
    "a = torch.tensor(2.0, requires_grad=True)\n",
    "b = torch.tensor(1.0, requires_grad=True)\n",
    "c = a + b\n",
    "d = b + 1\n",
    "e = c * d\n",
    "print(a, b, c, d, e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grad_fn stores information about computation\n",
    "print(c.grad_fn)\n",
    "print(e.grad_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we can computer derivative of $e$ w.r.t. $a, b, c, d$\n",
    "<img src=\"tree-eval-derivs.png\" alt=\"Drawing\" style=\"width: 600px;\"/>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation} \n",
    "e = c * d\n",
    "\\end{equation}\n",
    "\\begin{equation} \n",
    "\\frac {\\partial e} {\\partial c} = d = 2\n",
    "\\end{equation}\n",
    "\\begin{equation} \n",
    "\\frac {\\partial e} {\\partial d} = c = 3\n",
    "\\end{equation}\n",
    "\\begin{equation} \n",
    "\\frac {\\partial e} {\\partial a} = \\frac {\\partial e} {\\partial c} \\frac {\\partial c} {\\partial a} = 2\n",
    "\\end{equation}\n",
    "\\begin{equation} \n",
    "\\frac {\\partial e} {\\partial b} = \\frac {\\partial e} {\\partial c} \\frac {\\partial c} {\\partial b} + \\frac {\\partial e} {\\partial d} \\frac {\\partial d} {\\partial b} = 2 * 1 + 3 * 1 = 5\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute gradients with `torch.autograd.grad` https://pytorch.org/docs/stable/autograd.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute gradients with torch.autograd.grad https://pytorch.org/docs/stable/autograd.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_a, grad_b, grad_c, grad_d = torch.autograd.grad(e, [a, b, c, d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grad_a, grad_b, grad_c, grad_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another way for leaf tensors with `backward` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a and b\n",
    "# Compute c, d, e\n",
    "a = torch.tensor(2.0, requires_grad=True)\n",
    "b = torch.tensor(1.0, requires_grad=True)\n",
    "c = a + b\n",
    "d = b + 1\n",
    "e = c * d\n",
    "print(a, b, c, d, e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a.grad, b.grad, c.grad, d.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
